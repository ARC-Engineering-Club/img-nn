{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2/>\n",
    "This notebook explains Michael Nielsen's implementation of a simple, fully connected neural network.\n",
    "</h2>\n",
    "\n",
    "<br>\n",
    "A fully connected neural network works fairly well for recognizing grayscale images with low variation, such as pictures of digits and characters. For images that have greater variation, a convolutional neural network (CNN) is required. However, a convolutional network is simply an extension of a fully connected network, so it is necessary to understand how a more basic network works before moving on to CNNs.\n",
    "<br>\n",
    "\n",
    "Before reading this code, you should be fairly confident with reading and understanding Python syntax (or familiar enough in programming to figure it out). You should also be familiar with object-oriented concepts such as classes and objects. If you have any questions, post them in the ARC Engineering Club Discord or message/email a club officer. \n",
    "<br>\n",
    "\n",
    "For a more general and intuitive understanding of what the neural network is doing, it will be helpful to refer to <a href=\"https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi\"><b/>this</b></a> playlist of videos by 3Blue1Brown. <b/> I strongly recommend watching this playlist as it will make understanding the code implementation of the network much easier </b> However, I will try my best to write annotations assuming you have not watched the playlist.\n",
    "<br>\n",
    "\n",
    "So let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing the libraries that we will need for the neural network.\n",
    "<br>\n",
    "We will only be using two external packages, <i/>random</i> and <i/>numpy</i>.\n",
    "<ul>\n",
    "    <li><b>random</b> - This package implements pseudo-random number generators for various distributions.</li>\n",
    "    <li><b>numpy</b> - This package implements optimized linear algebra operations and data structures.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move on to the class header and constructor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have created a class that gets instantiated with a list called sizes. The list ``sizes`` contains the number of neurons in the respective layers of the network.  For example, if the list was [2, 3, 1] then it would be a three-layer network, with the first layer containing 2 neurons, the second layer 3 neurons, and the third layer 1 neuron.\n",
    "<br><br>\n",
    "An example instantiation of such a neural net would look like this: ``net = Network([2,3,1])``\n",
    "<br><br>\n",
    "To get a better feel for what is happening and what ``sizes`` represents, here is a visual representation of this example neural network.\n",
    "<br>\n",
    "<img src=\"https://i.gyazo.com/04f8ada656c619df79fd63d869c26d6b.png\" width=\"700\">\n",
    "<br>\n",
    "As you can see, the first layer contains 2 neurons, the second layer has 3 neurons, and the last layer has 1 neuron. ``sizes`` is just a list of the sizes for each layer. ``sizes[0]`` would give the size of the input layer, ``sizes[1]`` the size of the next, and so on up to the output layer.\n",
    "<br><br>\n",
    "``num_layers`` is a parameter that tracks the number of layers in the neural network. With our example, ``num_layers = 3``. The length of the ``sizes`` list gives us the number of layers.\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
